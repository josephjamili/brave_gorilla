{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "\n",
    "This project will simulate working as data analysts for a company that builds both Android and iOS mobile apps, with these apps being available on Google Play and the App Store, respectively. We are only building apps that are free to install and download, so the main source of revenue will be in-app ads. The more users who see and engage with the ads, the better our revenue.\n",
    "\n",
    "The goal of this project is to use the data to help our developers understand what type of apps are likely the attract more users.\n",
    "\n",
    "## Opening and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Google Play dataset\n",
    "opened_file = open('googleplaystore.csv')\n",
    "read_file = reader(opened_file)\n",
    "android = list(read_file)\n",
    "android_header = android[0]\n",
    "android = android[1:]\n",
    "\n",
    "# App Store dataset\n",
    "opened_file = open('AppleStore.csv')\n",
    "read_file = reader(opened_file)\n",
    "ios = list(read_file)\n",
    "ios_header = ios[0]\n",
    "ios= ios[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "\n",
    "print(android_header)\n",
    "print(explore_data(android, 0, 3, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ios_header)\n",
    "print('\\n')\n",
    "explore_data(ios, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Wrong Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android[10472])  # incorrect row\n",
    "print('\\n')\n",
    "print(android_header)  # header\n",
    "print('\\n')\n",
    "print(android[0])      # correct row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(android))\n",
    "del android[10472] # don't run this more than once\n",
    "print(len(android))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "    \n",
    "print('Number of duplicate apps:', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', duplicate_apps[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We're see that the Google Play dataset has duplicate entries, some of which were printed above to confirm this.\n",
    "\n",
    "We don't want to count certain apps more than once when we analyze the data, so we will need to remove the duplicates and only keep one entry per app. We could remove duplicate rows randomly,but we can find a better way. As seen below for the example using Instagram, the *fourth position (index) of each row corresponds to the number of reviews*. The different numbers indicate that the data was collected at different times.\n",
    "\n",
    "We can use the information in the fourth index as the criterion for removing duplicates - the higher the number of reviews, the more recent the data should be. We will aim to only keep the row with the highest number of reviews so that we keep fairly recent data while removing the other entries for any given app.\n",
    "\n",
    "---\n",
    "To remove the duplicates, we will do the following:\n",
    "1. Create a dictionary, where each dictionary key is a unique app name and the corresponding dictionary value is the highest number of reviews of that app.\n",
    "2. Use the information stored in the dictionary and create a new dataset, which will have only one entry per app. For each app, we'll only choose the entry with the highest number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "\n",
    "print('Expected length:', len(android) - 1181)\n",
    "print('Actual length:', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We use the dictionary created above to remove the duplicate rows.\n",
    "* Start by creating two empty lists: ```android_clean``` (which will store our new cleaned data set) and ```already_added``` (which has just store app names)\n",
    "* Loop through the Google Play dataset (without the header row), and for each iteration, do the following:\n",
    "    * Assign the app name to a variable names ```name```.\n",
    "    * Convert the number of reviews of ```float```, and assign it to a vairalbe named ```n_reviews```\n",
    "* if ```n_reviews``` is the same as the number of maximum reviews of the app ```name``` (the number can be found int he ```reviews_max``` dictionary) **and** ```name``` is not already in the list ```already_added```:\n",
    "    * Append the entire row to the ```android_clean``` list (which will eventulaly be a list of lists and store our cleaned dataset).\n",
    "    * Append the name of the app ```name``` to the ```already_added``` list - this helps us to keep track of apps that we already added.\n",
    "\n",
    "Explore the ```android_clean``` dataset to ensure everythign went as expected. The dataset should have 9,659 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if (reviews_max[name] == n_reviews) and (name not in already_added):\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name) # make sure this is inside the if block\n",
    "\n",
    "# we check to see if rows equals 9659\n",
    "explore_data(android_clean, 0, 3, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Only the Google Play dataset has duplicate entries. The App Store data does not have duplicates - this can be checked using the ```id``` column (not the ```track_name``` column).\n",
    "\n",
    "## Removing Non-English Apps\n",
    "\n",
    "Remeber that we use English for the apps we devleop at our company. We are not interested in keeping apps not made for English-speakers, so we'll remove them. We can do this by removing each app with a name containing a symbol that isn't common in English text - letters from the English alphabets, numbers composed of digist 0 to 9, punctation marks (.,!,?,;), and other symbols (+,*,/).\n",
    "\n",
    "Each character we use in a string has a corresponding humber associated with it. \n",
    "* The number for the character ```'a'``` is 97, character ```'A'``` is 65. We can get this humber using the [```ord()``` built-in function](https://docs.python.org/3/library/functions.html#ord). \n",
    "\n",
    "The numbers corresponding to the characters we normally use in an English text are all in the range 0 to 127, according to the [ASCII](https://en.wikipedia.org/wiki/ASCII) (American Standard Code for Information Interchange) system.\n",
    "* We can bulild a function that detects whether a character is equal to or less than 127 to determine if it has an English name. Therefore, it would be an app made for English-speakers.\n",
    "* We can use indexing to select and individual character, and we can also iterate on the string using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first try to write a function, then we'll remove the rows\n",
    "# corresponding to the non-English apps.\n",
    "print(ios[813][1])\n",
    "print(ios[6731][1])\n",
    "print('\\n')\n",
    "print(android_clean[4412][0])\n",
    "print(android_clean[7940][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(is_english('Instagram'))\n",
    "print(is_english('çˆ±å¥‡è‰ºPPS -ã€Šæ¬¢ä¹é¢‚2ã€‹ç”µè§†å‰§çƒ­æ’­'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuction above works, but some English apps an ames can use emojois or other symbols that are outside the ASCII range. This might cause us to remove English apps by mistake and lose useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_english('Docs To Goâ„¢ Free Office Suite'))\n",
    "print(is_english('Instachat ðŸ˜œ'))\n",
    "\n",
    "print(ord('â„¢'))\n",
    "print(ord('ðŸ˜œ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize this error, we'll only remove an app if its name has more than three characters with corresponding numbers falling outside the ASCII range. This isn't a perfect filter function, but it should be effective enough.\n",
    "\n",
    "We change the function as below; if the input string has more than three characters that are outside of ASCII range (0 - 127), then the function should identify as ```False```, otherwise it is ```True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            non_ascii += 1\n",
    "    \n",
    "    if non_ascii > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "print(is_english('Docs To Goâ„¢ Free Office Suite'))\n",
    "print(is_english('Instachat ðŸ˜œ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the new function to filter out non-English apps from both datasets. Loop through each dataset. If an app name is identified as English, append the whole row to a separate list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "android_english = []\n",
    "ios_english = []\n",
    "\n",
    "for app in android_clean:\n",
    "    name = app[0]\n",
    "    if is_english(name):\n",
    "        android_english.append(app)\n",
    "        \n",
    "for app in ios:\n",
    "    name = app[1]\n",
    "    if is_english(name):\n",
    "        ios_english.append(app)\n",
    "        \n",
    "explore_data(android_english, 0, 3, True)\n",
    "print('\\n')\n",
    "explore_data(ios_english, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Isolating the Free Apps\n",
    "\n",
    "So far, we have done the following:\n",
    "* Removed inaccurate data\n",
    "* Removed duplicate app entries\n",
    "* Removed non-English apps\n",
    "\n",
    "As mentioned in the beginning, we're focused on free apps. We will need to isolate these free apps for our analysis. Isolating these free apps will be the last step in our data cleaning process and we will start analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_free = []\n",
    "ios_free = []\n",
    "\n",
    "for app in android_english:\n",
    "    price = app[7]\n",
    "    if price == '0':\n",
    "        android_free.append(app)\n",
    "\n",
    "for app in ios_english:\n",
    "    price = app[4]\n",
    "    if price == '0.0':\n",
    "        ios_free.append(app)\n",
    "\n",
    "print(len(android_free))\n",
    "print(len(ios_free))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Most Common Apps by Genre\n",
    "\n",
    "Another objective stated in the beginning was that we wanted to focus on the kinds of apps that are likely to attract users, as the number of people engaging with our apps will affect our revenue.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea has three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and then add it to the App Store.\n",
    "\n",
    "The end goal is to add the app on both platforms so we will need to find app profiles that are successful in both markets. To begin analysts of the most common genres for each market, we'll need to build frequency tables for a few columns in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        value = row[index]\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "    \n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        percentage = (table[key] / total) * 100\n",
    "        table_percentages[key] = percentage\n",
    "        \n",
    "    return table_percentages\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we willl analyze first the App Store dataset, then the Google Play dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_table(ios_free, -5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For the iOS apps, we see the most common genres as **Games** at 58.2% and **Entertainment** at 7.9% This dataset seems to point towards more apps being geared towards entertainment versus practical applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_free, 1) #for Google Play category column\n",
    "print('\\n')\n",
    "display_table(android_free, 9) #for Google Play genre column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When looking at the **Category** column for the Android dataset, we see that **Family** and **Game** are the top two results, coming in at 18.9% and 9.7% respectively. In contrast to the results seen from the iOS dataset, the more popular apps on Google Play appear to cater more towards practical purposes as opposed to entertainment.\n",
    "\n",
    "The **Genre** column here also further supports this observation, with **Tools** being the most popular genre at 8.4% and **Entertainment** following behind at 6.1%. The Google Play store appears to be more balanced as opposed to the App Store, which seems to largely be geared towards fun and entertainment.\n",
    "\n",
    "It is interesting to note that Categories and Genres do not show an overwhelming majority of apps geared towards one kind of app but this may be because the Google Play store offers a more diverse range of applications compared to it's Apple counterpart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Most Popular Apps by Genre on the App Store\n",
    "\n",
    "Now we would like to see the apps with the most users. In the Google Play dataset, we can see this under the ```Installs``` column. However, the App Store dataset does not have this information. As a workaround, we will take the total number of user ratings as a proxy, which can be found in the ```rating_count_tot``` column.\n",
    "\n",
    "We start by finding the average number of user ratigs per app genre on the App Store. So we will need to do the folllwing:\n",
    "* Isolate apps of each genre\n",
    "* Add up the user ratings for the apps of that genre\n",
    "* Divide the sum by the number of apps belonging to that genre (not by the total number of apps)\n",
    "To do this, we will use a for loop inside of another for loop i.e. a **nested loop**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_ios = freq_table(ios_free, -5)\n",
    "\n",
    "for genre in genres_ios:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for app in ios_free:\n",
    "        genre_app = app[-5]\n",
    "        if genre_app == genre:            \n",
    "            n_ratings = float(app[5])\n",
    "            total += n_ratings\n",
    "            len_genre += 1\n",
    "    avg_n_ratings = total / len_genre\n",
    "    print(genre, ':', avg_n_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, navigation apps have the highest number of user reviews, but this is heavily influenced by Waze and Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in ios_free:\n",
    "    if app[-5] == 'Navigation':\n",
    "        print(app[1], ':', app[5]) # print name and number of ratings\n",
    "print('\\n')        \n",
    "for app in ios_free:\n",
    "    if app[-5] == 'Reference':\n",
    "        print(app[1], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same pattern applies to social networking apps and music apps.\n",
    "\n",
    "Our goal is to find popular genres, but navigation, social networking or music apps might seem more popular than they really are. We could get a better picture by removing extremely popular apps for each genre and then rework the averages.\n",
    "\n",
    "In the block above, refereance apps have 74,942 user ratings but the Bible and Dictionary.com that skey up the average rating.\n",
    "\n",
    "There is potential with this niche, where we can take a popular book and turn it into an app with extra features besides the book itself. The market does seem saturated here with apps meant for fun so a practical app might be able to stand out more in the App Store. Other categories liseted below do not seem to fit our scope for the analysis:\n",
    "* Weather apps - people do not spend as much time on these and so the ad revenue can be low.\n",
    "* Food and Drink - we would need to work with another company and the overhead costs for starting and running the app may be more than the revenue generated from ads alone.\n",
    "* Finance apps - we would require domain knowledge and a financial consultant/expert just to build an app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Most Popular Apps by Genre on Google Play\n",
    "\n",
    "When we try to look at the Play Store, most values are open-ended and the install numbers do not seem precise enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_free, 5) # the Installs columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with this data is that is not precise. For instance, we don't know whether an app with 100,000+ installs has 100,000 installs, 200,000, or 350,000. However, we don't need very precise data for our purposes â€” we only want to get an idea which app genres attract the most users, and we don't need perfect precision with respect to the number of users.\n",
    "\n",
    "We're going to leave the numbers as they are, which means that we'll consider that an app with 100,000+ installs has 100,000 installs, and an app with 1,000,000+ installs has 1,000,000 installs, and so on.\n",
    "\n",
    "To perform computations, however, we'll need to convert each install number to ```float``` â€” this means that we need to remove the commas and the plus characters, otherwise the conversion will fail and raise an error. We'll do this directly in the loop below, where we also compute the average number of installs for each genre (category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_android = freq_table(android_free, 1)\n",
    "\n",
    "for category in categories_android:\n",
    "    total = 0\n",
    "    len_category = 0\n",
    "    for app in android_free:\n",
    "        category_app = app[1]\n",
    "        if category_app == category:\n",
    "            n_installs = app[5]\n",
    "            n_installs = n_installs.replace(',', '')\n",
    "            n_installs = n_installs.replace('+', '')\n",
    "            total += float(n_installs)\n",
    "            len_category += 1\n",
    "    avg_n_installs = total / len_category\n",
    "    print(category, ':', avg_n_installs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, communication apps have the most installs: 38,456,119. This number is heavily skewed up by a few apps that have over one billion installs (WhatsApp, Facebook Messenger, Gmail) and some others with over 100 and 500 million installs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in android_free:\n",
    "    if app[1] == 'COMMUNICATION' and (app[5] == '1,000,000,000+'\n",
    "                                      or app[5] == '500,000,000+'\n",
    "                                      or app[5] == '100,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we removed all the communication apps with over 100 millsion installs, the average would be reduced by about ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_100_m = []\n",
    "\n",
    "for app in android_free:\n",
    "    n_installs = app[5]\n",
    "    n_installs = n_installs.replace(',', '')\n",
    "    n_installs = n_installs.replace('+', '')\n",
    "    if (app[1] == 'COMMUNICATION') and (float(n_installs) < 100000000):\n",
    "        under_100_m.append(float(n_installs))\n",
    "        \n",
    "sum(under_100_m) / len(under_100_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in an earlier analysis from the App Store that Games may be heavily saturated but books seemed to do well. We can explore this here as well as there are over 8 million installs for ```BOOKS AND REFERENCE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in android_free:\n",
    "    if app[1] == 'BOOKS_AND_REFERENCE':\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of apps seen in this category but there are still a number of very popular apps skewing the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in android_free:\n",
    "    if app[1] == 'BOOKS_AND_REFERENCE' and (app[5] == '1,000,000+'\n",
    "                                            or app[5] == '5,000,000+'\n",
    "                                            or app[5] == '10,000,000+'\n",
    "                                            or app[5] == '50,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This niche is dominated by apps for processing and reading ebooks, so perhaps it's best to steer clear from these. We also notice quite a few apps for the Quran, suggesting that building an app around a popular book can be profitable. \n",
    "\n",
    "It seems that taking a popular book (perhaps something more recent) and turning it into an app could be profitable for both the Google Play and App Store markets. It does look like there are enough libraries so we will need to add some speacial features to make our app more appealing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
